{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87312dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0b016",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7f1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to most_viewed_youtube_videos.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure 'chromedriver' is in your PATH\n",
    "\n",
    "# Open the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "# Give some time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Locate the table containing the most viewed YouTube videos\n",
    "table = driver.find_element(By.CLASS_NAME, 'wikitable')\n",
    "\n",
    "# Initialize lists to store the extracted details\n",
    "ranks = []\n",
    "names = []\n",
    "artists = []\n",
    "upload_dates = []\n",
    "views = []\n",
    "\n",
    "# Loop through the rows of the table and extract the details\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    \n",
    "    if len(cols) > 4:\n",
    "        ranks.append(cols[0].text.strip())\n",
    "        names.append(cols[1].text.strip())\n",
    "        artists.append(cols[2].text.strip())\n",
    "        upload_dates.append(cols[4].text.strip())\n",
    "        views.append(cols[3].text.strip())\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Rank': ranks,\n",
    "    'Name': names,\n",
    "    'Artist': artists,\n",
    "    'Upload date': upload_dates,\n",
    "    'Views': views\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('most_viewed_youtube_videos.csv', index=False)\n",
    "\n",
    "print(\"Data saved to most_viewed_youtube_videos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d787d50",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c8025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to india_international_fixtures.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure 'chromedriver' is in your PATH\n",
    "\n",
    "# Open the BCCI homepage\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Give some time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the international fixtures page\n",
    "fixtures_button = driver.find_element(By.XPATH, '/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixtures_button.click()\n",
    "\n",
    "# Give some time for the fixtures page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract fixtures details\n",
    "series_list = []\n",
    "place_list = []\n",
    "date_list = []\n",
    "time_list = []\n",
    "\n",
    "# Locate the fixtures elements\n",
    "fixtures = driver.find_elements(By.CLASS_NAME, 'js-list')\n",
    "\n",
    "for fixture in fixtures:\n",
    "    series = fixture.find_element(By.CLASS_NAME, 'fix-place').text.strip()\n",
    "    place = fixture.find_element(By.CLASS_NAME, 'fix-place').text.strip()\n",
    "    date_time = fixture.find_element(By.CLASS_NAME, 'match-dates').text.strip()\n",
    "    \n",
    "    # Split date and time if both are available\n",
    "    date, time = date_time.split(' ', 1) if ' ' in date_time else (date_time, '-')\n",
    "    \n",
    "    series_list.append(series)\n",
    "    place_list.append(place)\n",
    "    date_list.append(date)\n",
    "    time_list.append(time)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Series': series_list,\n",
    "    'Place': place_list,\n",
    "    'Date': date_list,\n",
    "    'Time': time_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('india_international_fixtures.csv', index=False)\n",
    "\n",
    "print(\"Data saved to india_international_fixtures.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d0794",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c03b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to site issue i am unable to scrap data problem statement not sufficient "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc5739",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eef10d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//summary[contains(text(), \"Explore\")]\"}\n  (Session info: chrome=125.0.6422.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977EBA]\n\t(No symbol) [0x00007FF6E09C7676]\n\t(No symbol) [0x00007FF6E09C773C]\n\t(No symbol) [0x00007FF6E0A0E967]\n\t(No symbol) [0x00007FF6E09EC25F]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Navigate to the \"Trending\" page through the \"Explore\" menu\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m explore_menu \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//summary[contains(text(), \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplore\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m ActionChains(driver)\u001b[38;5;241m.\u001b[39mmove_to_element(explore_menu)\u001b[38;5;241m.\u001b[39mperform()\n\u001b[0;32m     24\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//summary[contains(text(), \"Explore\")]\"}\n  (Session info: chrome=125.0.6422.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977EBA]\n\t(No symbol) [0x00007FF6E09C7676]\n\t(No symbol) [0x00007FF6E09C773C]\n\t(No symbol) [0x00007FF6E0A0E967]\n\t(No symbol) [0x00007FF6E09EC25F]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure 'chromedriver' is in your PATH\n",
    "\n",
    "# Open the Wikipedia page\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Give some time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the \"Trending\" page through the \"Explore\" menu\n",
    "explore_menu = driver.find_element(By.XPATH, '//summary[contains(text(), \"Explore\")]')\n",
    "ActionChains(driver).move_to_element(explore_menu).perform()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "trending_option = driver.find_element(By.XPATH, '//a[contains(text(), \"Trending\")]')\n",
    "trending_option.click()\n",
    "\n",
    "# Wait for the trending page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the scraped data\n",
    "repo_titles = []\n",
    "repo_descriptions = []\n",
    "contributors_counts = []\n",
    "languages_used = []\n",
    "\n",
    "# Locate all the repository elements on the trending page\n",
    "repos = driver.find_elements(By.CLASS_NAME, 'Box-row')\n",
    "\n",
    "for repo in repos:\n",
    "    # Scrape the repository title\n",
    "    try:\n",
    "        title = repo.find_element(By.TAG_NAME, 'h1').text\n",
    "    except:\n",
    "        title = '-'\n",
    "    repo_titles.append(title)\n",
    "\n",
    "    # Scrape the repository description\n",
    "    try:\n",
    "        description = repo.find_element(By.TAG_NAME, 'p').text\n",
    "    except:\n",
    "        description = '-'\n",
    "    repo_descriptions.append(description)\n",
    "\n",
    "    # Scrape the contributors count\n",
    "    try:\n",
    "        contributors = repo.find_elements(By.CSS_SELECTOR, 'a.Link--muted.d-inline-block.mr-3')\n",
    "        contributors_count = contributors[-1].text.strip()\n",
    "    except:\n",
    "        contributors_count = '-'\n",
    "    contributors_counts.append(contributors_count)\n",
    "\n",
    "    # Scrape the language used\n",
    "    try:\n",
    "        language = repo.find_element(By.CSS_SELECTOR, '[itemprop=\"programmingLanguage\"]').text\n",
    "    except:\n",
    "        language = '-'\n",
    "    languages_used.append(language)\n",
    "      \n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Repository Title': repo_titles,\n",
    "    'Repository Description': repo_descriptions,\n",
    "    'Contributors Count': contributors_counts,\n",
    "    'Language Used': languages_used\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('trending_repositories_github.csv', index=False)\n",
    "\n",
    "print(\"Data saved to trending_repositories_github.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb23fc",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd70b55d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=125.0.6422.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977CE9]\n\t(No symbol) [0x00007FF6E09C89C2]\n\t(No symbol) [0x00007FF6E09BB491]\n\t(No symbol) [0x00007FF6E09EC21A]\n\t(No symbol) [0x00007FF6E09BADB6]\n\t(No symbol) [0x00007FF6E09EC430]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Navigate to the \"Hot 100\" page through the \"Charts\" menu\u001b[39;00m\n\u001b[0;32m      9\u001b[0m charts_menu \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m charts_menu\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     12\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m hot_100_link \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mCLICK_ELEMENT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=125.0.6422.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977CE9]\n\t(No symbol) [0x00007FF6E09C89C2]\n\t(No symbol) [0x00007FF6E09BB491]\n\t(No symbol) [0x00007FF6E09EC21A]\n\t(No symbol) [0x00007FF6E09BADB6]\n\t(No symbol) [0x00007FF6E09EC430]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n"
     ]
    }
   ],
   "source": [
    "# Open the Billboard homepage\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the \"Hot 100\" page through the \"Charts\" menu\n",
    "charts_menu = driver.find_element(By.XPATH, '/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a')\n",
    "charts_menu.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "hot_100_link = driver.find_element(By.XPATH, '/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "hot_100_link.click()\n",
    "\n",
    "# Wait for the Hot 100 page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the scraped data\n",
    "song_names = []\n",
    "artist_names = []\n",
    "last_week_ranks = []\n",
    "peak_ranks = []\n",
    "weeks_on_board = []\n",
    "\n",
    "# Locate all the song elements on the Hot 100 page\n",
    "songs = driver.find_elements(By.CSS_SELECTOR, 'li.o-chart-results-list__item')\n",
    "\n",
    "for song in songs:\n",
    "    # Scrape the song name\n",
    "    try:\n",
    "        song_name = song.find_element(By.CSS_SELECTOR, 'h3.c-title.a-no-trucate').text.strip()\n",
    "    except:\n",
    "        song_name = '-'\n",
    "    song_names.append(song_name)\n",
    "\n",
    "    # Scrape the artist name\n",
    "    try:\n",
    "        artist_name = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-no-trucate').text.strip()\n",
    "    except:\n",
    "        artist_name = '-'\n",
    "    artist_names.append(artist_name)\n",
    "\n",
    "    # Scrape the last week rank\n",
    "    try:\n",
    "        last_week_rank = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-s').text.strip()\n",
    "    except:\n",
    "        last_week_rank = '-'\n",
    "    last_week_ranks.append(last_week_rank)\n",
    "\n",
    "    # Scrape the peak rank\n",
    "    try:\n",
    "        peak_rank = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-s:nth-child(2)').text.strip()\n",
    "    except:\n",
    "        peak_rank = '-'\n",
    "    peak_ranks.append(peak_rank)\n",
    "\n",
    "    # Scrape the weeks on board\n",
    "    try:\n",
    "        weeks_on_board = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-s:nth-child(3)').text.strip()\n",
    "    except:\n",
    "        weeks_on_board = '-'\n",
    "    weeks_on_board.append(weeks_on_board)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Song Name': song_names,\n",
    "    'Artist Name': artist_names,\n",
    "    'Last Week Rank': last_week_ranks,\n",
    "    'Peak Rank': peak_ranks,\n",
    "    'Weeks on Board': weeks_on_board\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('billboard_hot_100_songs.csv', index=False)\n",
    "\n",
    "print(\"Data saved to billboard_hot_100_songs.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057535f6",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50ccf3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to highest_selling_novels.csv\n"
     ]
    }
   ],
   "source": [
    "# Open the specified URL\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Locate the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//table[contains(@class, \"in-article sortable\")]')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')[1:]  # Skip the header row\n",
    "\n",
    "# Lists to store the scraped data\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "# Extract data from each row\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    \n",
    "    if len(cells) < 5:\n",
    "        continue  # Skip rows that don't have enough columns\n",
    "    \n",
    "    book_name = cells[0].text.strip()\n",
    "    author_name = cells[1].text.strip()\n",
    "    volume_sold = cells[2].text.strip()\n",
    "    publisher = cells[3].text.strip()\n",
    "    genre = cells[4].text.strip()\n",
    "    \n",
    "    book_names.append(book_name)\n",
    "    author_names.append(author_name)\n",
    "    volumes_sold.append(volume_sold)\n",
    "    publishers.append(publisher)\n",
    "    genres.append(genre)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Book Name': book_names,\n",
    "    'Author Name': author_names,\n",
    "    'Volumes Sold': volumes_sold,\n",
    "    'Publisher': publishers,\n",
    "    'Genre': genres\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('highest_selling_novels.csv', index=False)\n",
    "\n",
    "print(\"Data saved to highest_selling_novels.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc259a",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adea52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to most_watched_tv_series.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the specified URL\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the scraped data\n",
    "names = []\n",
    "year_spans = []\n",
    "genres = []\n",
    "run_times = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "# Locate the container with TV series details\n",
    "containers = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]')\n",
    "\n",
    "for container in containers:\n",
    "    # Name\n",
    "    name = container.find_element(By.XPATH, './/h3/a').text\n",
    "    names.append(name)\n",
    "    \n",
    "    # Year span\n",
    "    year_span = container.find_element(By.XPATH, './/h3/span[contains(@class, \"lister-item-year\")]').text\n",
    "    year_spans.append(year_span)\n",
    "    \n",
    "    # Genre\n",
    "    genre = container.find_element(By.XPATH, './/p/span[@class=\"genre\"]').text.strip()\n",
    "    genres.append(genre)\n",
    "    \n",
    "    # Run time\n",
    "    try:\n",
    "        run_time = container.find_element(By.XPATH, './/p/span[@class=\"runtime\"]').text\n",
    "    except:\n",
    "        run_time = \"-\"\n",
    "    run_times.append(run_time)\n",
    "    \n",
    "    # Ratings\n",
    "    try:\n",
    "        rating = container.find_element(By.XPATH, './/div[contains(@class, \"ratings-imdb-rating\")]/strong').text\n",
    "    except:\n",
    "        rating = \"-\"\n",
    "    ratings.append(rating)\n",
    "    \n",
    "    # Votes\n",
    "    try:\n",
    "        vote = container.find_element(By.XPATH, './/span[@name=\"nv\"]').text\n",
    "    except:\n",
    "        vote = \"-\"\n",
    "    votes.append(vote)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Name': names,\n",
    "    'Year Span': year_spans,\n",
    "    'Genre': genres,\n",
    "    'Run Time': run_times,\n",
    "    'Ratings': ratings,\n",
    "    'Votes': votes\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('most_watched_tv_series.csv', index=False)\n",
    "\n",
    "print(\"Data saved to most_watched_tv_series.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bc28a",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf5b2311",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"View All Collections\"}\n  (Session info: chrome=125.0.6422.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977EBA]\n\t(No symbol) [0x00007FF6E09C7676]\n\t(No symbol) [0x00007FF6E09C773C]\n\t(No symbol) [0x00007FF6E0A0E967]\n\t(No symbol) [0x00007FF6E09EC25F]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Click on the \"View All Datasets\" link\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m view_all_datasets_link \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mLINK_TEXT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mView All Collections\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m view_all_datasets_link\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Wait for the page to load\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"View All Collections\"}\n  (Session info: chrome=125.0.6422.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6E0B41F52+60322]\n\t(No symbol) [0x00007FF6E0ABCEC9]\n\t(No symbol) [0x00007FF6E0977EBA]\n\t(No symbol) [0x00007FF6E09C7676]\n\t(No symbol) [0x00007FF6E09C773C]\n\t(No symbol) [0x00007FF6E0A0E967]\n\t(No symbol) [0x00007FF6E09EC25F]\n\t(No symbol) [0x00007FF6E0A0BC80]\n\t(No symbol) [0x00007FF6E09EBFC3]\n\t(No symbol) [0x00007FF6E09B9617]\n\t(No symbol) [0x00007FF6E09BA211]\n\tGetHandleVerifier [0x00007FF6E0E594AD+3301629]\n\tGetHandleVerifier [0x00007FF6E0EA36D3+3605283]\n\tGetHandleVerifier [0x00007FF6E0E99450+3563680]\n\tGetHandleVerifier [0x00007FF6E0BF4326+790390]\n\t(No symbol) [0x00007FF6E0AC750F]\n\t(No symbol) [0x00007FF6E0AC3404]\n\t(No symbol) [0x00007FF6E0AC3592]\n\t(No symbol) [0x00007FF6E0AB2F9F]\n\tBaseThreadInitThunk [0x00007FFD6AF07034+20]\n\tRtlUserThreadStart [0x00007FFD6C8826A1+33]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the UCI Machine Learning Repository homepage\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the \"View All Datasets\" link\n",
    "view_all_datasets_link = driver.find_element(By.LINK_TEXT, 'View All Collections')\n",
    "view_all_datasets_link.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the scraped data\n",
    "dataset_names = []\n",
    "data_types = []\n",
    "tasks = []\n",
    "attribute_types = []\n",
    "no_of_instances = []\n",
    "no_of_attributes = []\n",
    "years = []\n",
    "\n",
    "# Locate the table containing dataset details\n",
    "table = driver.find_element(By.XPATH, '//table[@border=\"1\"]')\n",
    "rows = table.find_elements(By.XPATH, './/tr')[1:]  # Skip the header row\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    dataset_names.append(cells[0].text)\n",
    "    data_types.append(cells[1].text)\n",
    "    tasks.append(cells[2].text)\n",
    "    attribute_types.append(cells[3].text)\n",
    "    no_of_instances.append(cells[4].text)\n",
    "    no_of_attributes.append(cells[5].text)\n",
    "    years.append(cells[6].text)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame to store the extracted details\n",
    "data = {\n",
    "    'Dataset Name': dataset_names,\n",
    "    'Data Type': data_types,\n",
    "    'Task': tasks,\n",
    "    'Attribute Type': attribute_types,\n",
    "    'No of Instances': no_of_instances,\n",
    "    'No of Attributes': no_of_attributes,\n",
    "    'Year': years\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('uci_datasets.csv', index=False)\n",
    "\n",
    "print(\"Data saved to uci_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da35136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
