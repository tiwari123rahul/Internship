{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e484b646",
   "metadata": {},
   "source": [
    "# Beautiful Soup Practice Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056cf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24168122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27819244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1: Wikipedia\n",
      "\n",
      "The Free Encyclopedia\n",
      "h2: 1,000,000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2: 100,000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2: 10,000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2: 1,000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2: 100+\n",
      "\n",
      "\n",
      "articles\n"
     ]
    }
   ],
   "source": [
    "#Solution\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a GET request to the Wikipedia homepage\n",
    "response = requests.get(\"https://www.wikipedia.org/\")\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all header tags (h1, h2, h3, h4, h5, h6)\n",
    "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "# Display the header tags with their text content\n",
    "for tag in header_tags:\n",
    "    print(f\"{tag.name}: {tag.text.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8dc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2: Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3348fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the page. Please check the URL or your connection.\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for IMDB's Top 250 movies\n",
    "url = \"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\"\n",
    "\n",
    "# Retrieve the page content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page. Please check the URL or your connection.\")\n",
    "else:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the table containing the top 100 movies\n",
    "    movie_table = soup.find(\"tbody\", class_=\"lister-list\")\n",
    "\n",
    "    if movie_table is None:\n",
    "        print(\"Failed to find the movie table. The page structure may have changed.\")\n",
    "    else:\n",
    "        # Lists to store the extracted data\n",
    "        movies = []\n",
    "        ratings = []\n",
    "        years = []\n",
    "\n",
    "        # Extract movie details from the table rows\n",
    "        for row in movie_table.find_all(\"tr\")[:100]:  # limiting to top 100\n",
    "            # Get the title of the movie\n",
    "            title = row.find(\"td\", class_=\"titleColumn\").a.text\n",
    "            # Get the rating\n",
    "            rating = row.find(\"td\", class_=\"ratingColumn\").strong.text\n",
    "            # Get the year of release (strip parentheses)\n",
    "            year = row.find(\"span\", class_=\"secondaryInfo\").text.strip(\"()\")\n",
    "\n",
    "            # Append the details to the respective lists\n",
    "            movies.append(title)\n",
    "            ratings.append(rating)\n",
    "            years.append(year)\n",
    "\n",
    "        # Create a DataFrame with the collected data\n",
    "        imdb_top_100 = pd.DataFrame({\n",
    "            \"Movie Name\": movies,\n",
    "            \"Rating\": ratings,\n",
    "            \"Year of Release\": years\n",
    "        })\n",
    "\n",
    "        # Display the DataFrame\n",
    "        print(imdb_top_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566f6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3: Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d48ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Restaurant Name  \\\n",
      "0                  Delia My Bar Headquarters   \n",
      "1                        My Bar Headquarters   \n",
      "2                                    Berco's   \n",
      "3                              The G.T. Road   \n",
      "4                                 Article 21   \n",
      "5                           Minar Restaurant   \n",
      "6                        Unplugged Courtyard   \n",
      "7                               Punjab Grill   \n",
      "8                                      Slice   \n",
      "9                                    Nando's   \n",
      "10                            Hard Rock Cafe   \n",
      "11                        Kwality Restaurant   \n",
      "12                                    Subway   \n",
      "13                                   Fa Yian   \n",
      "14                                  Cafe MRP   \n",
      "15                                 Oddly Pub   \n",
      "16                                     Local   \n",
      "17                             Kill The Bill   \n",
      "18                               The Embassy   \n",
      "19  Desi Villagio - Village Theme Restro Bar   \n",
      "\n",
      "                                              Cuisine  \\\n",
      "0         North Indian, Chinese, Fast Food, Beverages   \n",
      "1                               North Indian, Chinese   \n",
      "2                                       Chinese, Thai   \n",
      "3                                        North Indian   \n",
      "4                 North Indian, Chinese, South Indian   \n",
      "5                               North Indian, Chinese   \n",
      "6   North Indian, Italian, Chinese, Turkish, Conti...   \n",
      "7                               North Indian, Mughlai   \n",
      "8                                  Italian, Fast Food   \n",
      "9      Portuguese, Mediterranean, Desserts, Beverages   \n",
      "10                 American, Continental, Finger Food   \n",
      "11                 North Indian, Continental, Mughlai   \n",
      "12                                          Fast Food   \n",
      "13                                            Chinese   \n",
      "14  North Indian, Continental, Italian, Finger Foo...   \n",
      "15        North Indian, Chinese, Italian, Continental   \n",
      "16                   North Indian, Asian, Continental   \n",
      "17  Fast Food, North Indian, Seafood, Chinese, Con...   \n",
      "18  North Indian, European, Fast Food, Italian, Co...   \n",
      "19                                       North Indian   \n",
      "\n",
      "                                             Location Ratings  \\\n",
      "0                           Karol Bagh, Central Delhi     4.2   \n",
      "1                      Connaught Place, Central Delhi       4   \n",
      "2                      Connaught Place, Central Delhi     4.3   \n",
      "3              M-Block,Connaught Place, Central Delhi     4.3   \n",
      "4                      Connaught Place, Central Delhi     3.8   \n",
      "5                      Connaught Place, Central Delhi     4.4   \n",
      "6                      Connaught Place, Central Delhi       4   \n",
      "7                              Janpath, Central Delhi     3.7   \n",
      "8                      Connaught Place, Central Delhi     N/A   \n",
      "9              M-Block,Connaught Place, Central Delhi     4.4   \n",
      "10                     Connaught Place, Central Delhi     N/A   \n",
      "11  Regal Cinema Complex,Connaught Place, Central ...     4.4   \n",
      "12                     Connaught Place, Central Delhi     N/A   \n",
      "13                     Connaught Place, Central Delhi     N/A   \n",
      "14                     Connaught Place, Central Delhi     N/A   \n",
      "15                     Connaught Place, Central Delhi     N/A   \n",
      "16       Scindia House,Connaught Place, Central Delhi       4   \n",
      "17                     Connaught Place, Central Delhi     4.3   \n",
      "18                     Connaught Place, Central Delhi     4.1   \n",
      "19                     Connaught Place, Central Delhi     4.1   \n",
      "\n",
      "                                            Image URL  \n",
      "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
      "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "19  https://im1.dineout.co.in/images/uploads/resta...  \n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website to scrape\n",
    "url = \"https://www.dineout.co.in/delhi-restaurants\"  # Modify the URL if needed\n",
    "\n",
    "# Send a GET request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page. Please check the URL or your connection.\")\n",
    "else:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all the restaurant containers\n",
    "    restaurant_cards = soup.find_all(\"div\", class_=\"restnt-card restaurant\")\n",
    "\n",
    "    # Lists to store the extracted data\n",
    "    names = []\n",
    "    cuisines = []\n",
    "    locations = []\n",
    "    ratings = []\n",
    "    image_urls = []\n",
    "\n",
    "    # Loop through each restaurant card and extract details\n",
    "    for card in restaurant_cards:\n",
    "        # Restaurant name\n",
    "        name = card.find(\"div\", class_=\"restnt-info\").a.text.strip()\n",
    "        names.append(name)\n",
    "\n",
    "        # Cuisine\n",
    "        cuisine = card.find(\"span\", class_=\"double-line-ellipsis\").text.split('|')[1].strip()\n",
    "        cuisines.append(cuisine)\n",
    "\n",
    "        # Location\n",
    "        location = card.find(\"div\", class_=\"restnt-loc ellipsis\").text.strip()\n",
    "        locations.append(location)\n",
    "\n",
    "        # Rating\n",
    "        rating_tag = card.find(\"div\", class_=\"restnt-rating rating-4\")\n",
    "        rating = rating_tag.text.strip() if rating_tag else \"N/A\"  # Some might not have ratings\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Image URL\n",
    "        image_url = card.find(\"img\", class_=\"no-img\")['data-src']\n",
    "        image_urls.append(image_url)\n",
    "\n",
    "    # Create a DataFrame with the extracted data\n",
    "    restaurants_df = pd.DataFrame({\n",
    "        \"Restaurant Name\": names,\n",
    "        \"Cuisine\": cuisines,\n",
    "        \"Location\": locations,\n",
    "        \"Ratings\": ratings,\n",
    "        \"Image URL\": image_urls\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(restaurants_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8831984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4: Write s python program to display list of respected former finance minister of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9a643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the page. Please check the URL or your connection.\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL for the list of former Presidents of India\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page. Please check the URL or your connection.\")\n",
    "else:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the list of former Presidents\n",
    "    presidents_section = soup.find(\"div\", class_=\"presidentListing\")\n",
    "\n",
    "    # Lists to store the extracted data\n",
    "    names = []\n",
    "    terms = []\n",
    "\n",
    "    # Find all presidents in the section\n",
    "    if presidents_section:\n",
    "        president_entries = presidents_section.find_all(\"div\", class_=\"presidentListing\")\n",
    "\n",
    "        for entry in president_entries:\n",
    "            # Extract the name\n",
    "            name = entry.find(\"div\", class_=\"presidentName\").text.strip()\n",
    "            names.append(name)\n",
    "\n",
    "            # Extract the term of office\n",
    "            term = entry.find(\"div\", class_=\"presidentTerm\").text.strip()\n",
    "            terms.append(term)\n",
    "\n",
    "        # Create a DataFrame with the collected data\n",
    "        presidents_df = pd.DataFrame({\n",
    "            \"Name\": names,\n",
    "            \"Term of Office\": terms\n",
    "        })\n",
    "\n",
    "        # Display the DataFrame\n",
    "        print(presidents_df)\n",
    "    else:\n",
    "        print(\"Could not find the list of former Presidents on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc6d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
