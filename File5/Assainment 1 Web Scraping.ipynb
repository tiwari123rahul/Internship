{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7699a0c",
   "metadata": {},
   "source": [
    "# Assainment 1 Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba24a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Write a python program to display IMDB’s Top rated 100 Indian movies’ data https://www.imdb.com/list/ls056092300/ (i.e. name, rating, year ofrelease) and make data frame.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32159a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56643307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Movie Name Rating Year of Release\n",
      "0                     Ship of Theseus      8            2012\n",
      "1                              Iruvar    8.4            1997\n",
      "2                     Kaagaz Ke Phool    7.8            1959\n",
      "3   Lagaan: Once Upon a Time in India    8.1            2001\n",
      "4                     Pather Panchali    8.2            1955\n",
      "..                                ...    ...             ...\n",
      "95                        Apur Sansar    8.4            1959\n",
      "96                        Kanchivaram    8.2            2008\n",
      "97                    Monsoon Wedding    7.3            2001\n",
      "98                              Black    8.1            2005\n",
      "99                            Deewaar      8            1975\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Solution :\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for IMDB's Top 100 Indian movies\n",
    "url = \"https://www.imdb.com/list/ls056092300/\"\n",
    "\n",
    "# Retrieve the page content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page. Please check the URL or your connection.\")\n",
    "else:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all movie containers in the list\n",
    "    movie_containers = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "\n",
    "    # Lists to store the extracted data\n",
    "    movies = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    # Extract movie details from each container\n",
    "    for movie in movie_containers:\n",
    "        # Movie name\n",
    "        title = movie.find(\"a\").text.strip()\n",
    "        movies.append(title)\n",
    "\n",
    "        # Movie rating\n",
    "        rating_tag = movie.find(\"span\", class_=\"ipl-rating-star__rating\")\n",
    "        rating = rating_tag.text.strip() if rating_tag else \"N/A\"  # Some may not have ratings\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Movie year of release\n",
    "        year_tag = movie.find(\"span\", class_=\"lister-item-year\")\n",
    "        year = year_tag.text.strip(\"()\")  # Strip parentheses from year\n",
    "        years.append(year)\n",
    "\n",
    "    # Create a DataFrame with the collected data\n",
    "    top_100_indian_movies = pd.DataFrame({\n",
    "        \"Movie Name\": movies,\n",
    "        \"Rating\": ratings,\n",
    "        \"Year of Release\": years\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(top_100_indian_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abb461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3e9ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7: Please visit https://www.cnbc.com/world/?region=world and scrap- \n",
    "#a) headings \n",
    "#b) date \n",
    "#c) News link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58233de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Heading Date  \\\n",
      "0   All the data so far is showing inflation isn't...  N/A   \n",
      "1   S&P 500 posts best week since November, Nasdaq...  N/A   \n",
      "2   Exxon is working on tech to remove CO2 from at...  N/A   \n",
      "3   Zelenskyy says U.S. aid delay let Russia grab ...  N/A   \n",
      "4   Ukraine can keep on fighting Russia. The victo...  N/A   \n",
      "5   5 things to know before the stock market opens...  N/A   \n",
      "6   Russian strikes hit Ukrainian critical infrast...  N/A   \n",
      "7   Ukraine uses long-range ATACMS against Russia ...  N/A   \n",
      "8   Nowhere for the water to go: Dubai flooding sh...  N/A   \n",
      "9   Swiss women win historic victory at Europe's t...  N/A   \n",
      "10  Philippines' environment secretary on climate ...  N/A   \n",
      "11  March marks yet another global heat record, al...  N/A   \n",
      "12  How this UK-based firm is growing a more susta...  N/A   \n",
      "13  AirPods, Rolexes and Louis Vuitton bags: Store...  N/A   \n",
      "14  The cost to ride on India's luxury trains may ...  N/A   \n",
      "15     An introvert’s guide to surviving group travel  N/A   \n",
      "16  What’s your single best tip for traveling in J...  N/A   \n",
      "17  Richard Branson’s cruise line launches month-l...  N/A   \n",
      "18  Researcher who has interviewed 100+ people abo...  N/A   \n",
      "19  Should you take a gap year before college? 3 f...  N/A   \n",
      "20  This is the salary it takes to be considered r...  N/A   \n",
      "21  30-year-old hairstylist supercommutes over 500...  N/A   \n",
      "22  Selena Gomez says success of Rare Beauty's mis...  N/A   \n",
      "23  eVTOLS: Are flying cars finally becoming reality?  N/A   \n",
      "24                  How China's property bubble burst  N/A   \n",
      "25                  What is the World Economic Forum?  N/A   \n",
      "26  The Quad is going beyond military exercises — ...  N/A   \n",
      "27     Why a coup in Guinea was felt around the world  N/A   \n",
      "\n",
      "                                            News Link  \n",
      "0   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "1   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "2   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "3   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "4   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "5   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "6   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "7   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "8   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "9   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "10  https://www.cnbc.comhttps://www.cnbc.com/video...  \n",
      "11  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "12  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "13  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "14  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "15  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "16  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "17  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "18  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "19  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "20  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "21  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "22  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "23  https://www.cnbc.comhttps://www.cnbc.com/video...  \n",
      "24  https://www.cnbc.comhttps://www.cnbc.com/video...  \n",
      "25  https://www.cnbc.comhttps://www.cnbc.com/video...  \n",
      "26  https://www.cnbc.comhttps://www.cnbc.com/video...  \n",
      "27  https://www.cnbc.comhttps://www.cnbc.com/video...  \n"
     ]
    }
   ],
   "source": [
    "#Solution\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL for CNBC's World news section\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page. Please check the URL or your connection.\")\n",
    "else:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find news articles (adjust class names if necessary)\n",
    "    article_cards = soup.find_all(\"div\", class_=\"Card-titleContainer\")\n",
    "\n",
    "    # Lists to store extracted data\n",
    "    headings = []\n",
    "    dates = []\n",
    "    news_links = []\n",
    "\n",
    "    # Extract details from the article cards\n",
    "    for card in article_cards:\n",
    "        # Heading (title of the news)\n",
    "        heading = card.find(\"a\", class_=\"Card-title\").text.strip() if card.find(\"a\", class_=\"Card-title\") else \"N/A\"\n",
    "        headings.append(heading)\n",
    "\n",
    "        # News link\n",
    "        news_link = card.find(\"a\", class_=\"Card-title\")['href'] if card.find(\"a\", class_=\"Card-title\") else \"N/A\"\n",
    "        # Complete the relative URL to an absolute one\n",
    "        full_news_link = \"https://www.cnbc.com\" + news_link\n",
    "        news_links.append(full_news_link)\n",
    "\n",
    "        # Date is not typically shown on the main page, but let's check\n",
    "        date_tag = card.find(\"time\")\n",
    "        date = date_tag['datetime'] if date_tag else \"N/A\"\n",
    "        dates.append(date)\n",
    "\n",
    "    # Create a DataFrame with the collected data\n",
    "    news_df = pd.DataFrame({\n",
    "        \"Heading\": headings,\n",
    "        \"Date\": dates,\n",
    "        \"News Link\": news_links\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd258b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218525c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
